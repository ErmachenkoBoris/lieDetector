{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Deception-demo.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EEVZr8pjiAnI",
        "outputId": "857d9b96-277b-4e35-8d2b-3ec7b9d7866b"
      },
      "source": [
        "!pip install tensorflow_addons -q\n",
        "!pip install git+https://github.com/rcmalli/keras-vggface.git -q\n",
        "!pip install kapre==0.1.7 -q\n",
        "!pip install keras -q\n",
        "!pip install keras_applications -q\n",
        "!pip install opensmile -q\n",
        "!pip install torch -q"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  Building wheel for keras-vggface (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g0xNUreVh_bo",
        "outputId": "72a674fe-da09-4678-e621-ec8d7c2f3a80"
      },
      "source": [
        "!git clone https://github.com/ErmachenkoBoris/lieDetector.git"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "fatal: destination path 'lieDetector' already exists and is not an empty directory.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rmEQbMeYiOEG"
      },
      "source": [
        "import sys\n",
        "sys.path.append('/content/lieDetector')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ULLuiVW-Wx7s",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2eff1224-bae5-4631-89e1-bcdfc743f6f6"
      },
      "source": [
        "import os\n",
        "import csv\n",
        "import numpy as np\n",
        "import librosa as lb\n",
        "import librosa\n",
        "import opensmile\n",
        "import tensorflow as tf\n",
        "import torch\n",
        "import torchvision\n",
        "import cv2\n",
        "import math\n",
        "import cv2\n",
        "import numpy as np\n",
        "import opensmile\n",
        "import resampy\n",
        "import tensorflow as tf\n",
        "from kapre.time_frequency import Melspectrogram\n",
        "from keras import Model\n",
        "from keras_vggface import VGGFace\n",
        "\n",
        "from dataset.tf_example_writer import TfExampleWriter\n",
        "from utils.dirs import create_dirs\n",
        "from random import shuffle\n",
        "from numbers import Real\n",
        "\n",
        "import cv2\n",
        "import numpy as np\n",
        "import opensmile\n",
        "import resampy\n",
        "import random"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "SoX could not be found!\n",
            "\n",
            "    If you do not have SoX, proceed here:\n",
            "     - - - http://sox.sourceforge.net/ - - -\n",
            "\n",
            "    If you do (or think that you should) have SoX, double-check your\n",
            "    path variables.\n",
            "    \n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DhZJbqFCYZFm"
      },
      "source": [
        "# Конфигурация"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8nvmMdW9Pw2h"
      },
      "source": [
        "import torch\n",
        "\n",
        "device = torch.device('cuda:0')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cye5_OLAoYwp"
      },
      "source": [
        "from enum import Enum\n",
        "import tensorflow as tf\n",
        "from abc import ABC\n",
        "\n",
        "\n",
        "class TimeDependentModality(ABC):\n",
        "    WINDOW_STEP_IN_SECS = 1\n",
        "    WINDOW_WIDTH_IN_SECS = 5\n",
        "\n",
        "\n",
        "class VideoModalityConfig(TimeDependentModality):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.FRAMES_PERIOD = 5\n",
        "        self.SHAPE = 224\n",
        "        self.FPS = 32\n",
        "        self.FILE_EXT = '.mp4'\n",
        "\n",
        "\n",
        "class PulseConfig(TimeDependentModality):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.FPS = 50\n",
        "        self.SHAPE = 224\n",
        "        self.FILE_EXT = '.mp4'\n",
        "\n",
        "\n",
        "class VideoSceneModalityConfig(VideoModalityConfig):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.FILE_EXT = '.mp4'\n",
        "\n",
        "\n",
        "class AudioModalityConfig(TimeDependentModality):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.SR = 48000\n",
        "        self.FILE_EXT = '.wav'\n",
        "\n",
        "\n",
        "class Modality(Enum):\n",
        "    def __new__(cls, *args, **kwds):\n",
        "        value = len(cls.__members__) + 1\n",
        "        obj = object.__new__(cls)\n",
        "        obj._value_ = value\n",
        "        return obj\n",
        "\n",
        "    def __init__(self, config):\n",
        "        self.config = config\n",
        "\n",
        "    AUDIO = AudioModalityConfig()\n",
        "    VIDEO_FACE = VideoModalityConfig()\n",
        "    VIDEO_SCENE = VideoSceneModalityConfig()\n",
        "    PULSE = PulseConfig()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mtFjqXyeYSbk"
      },
      "source": [
        "PRETRAINED_MODELS = \"/content/drive/MyDrive/pretrained/\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4hdo2KjIpmol"
      },
      "source": [
        "class ByteEncoder:\n",
        "    def transform(self, feature):\n",
        "        return tf.train.Feature(bytes_list=tf.train.BytesList(value=[feature]))\n",
        "\n",
        "\n",
        "class IntEncoder:\n",
        "    def transform(self, feature):\n",
        "        return tf.train.Feature(int64_list=tf.train.Int64List(value=[feature]))\n",
        "\n",
        "\n",
        "class TensorEncoder(ByteEncoder):\n",
        "    def transform(self, feature):\n",
        "        feature = tf.io.serialize_tensor(tf.constant(feature)).numpy()\n",
        "        return super().transform(feature)\n",
        "\n",
        "\n",
        "class FeaturesSetConfig:\n",
        "    def __init__(self, shape, input_shape=None):\n",
        "        self.shape = shape\n",
        "        self.input_shape = input_shape if input_shape is not None else shape\n",
        "\n",
        "\n",
        "class DatasetFeaturesSet(Enum):\n",
        "    def __new__(cls, *args, **kwds):\n",
        "        value = len(cls.__members__) + 1\n",
        "        obj = object.__new__(cls)\n",
        "        obj._value_ = value\n",
        "        return obj\n",
        "\n",
        "    def __init__(self, encoder, config):\n",
        "        self.encoder = encoder\n",
        "        self.config = config\n",
        "\n",
        "    OPENSMILE_ComParE_2016 = TensorEncoder(), FeaturesSetConfig(shape=(10, 6373), input_shape=(10, 6373))\n",
        "    AUDIO = TensorEncoder(), FeaturesSetConfig(shape=(10, 512), input_shape=(10, 512))\n",
        "    VIDEO_FACE = TensorEncoder(), FeaturesSetConfig(shape=0)\n",
        "    VIDEO_SCENE = TensorEncoder(), FeaturesSetConfig(shape=0)\n",
        "    PULSE = TensorEncoder(), FeaturesSetConfig(shape=(33, 512))\n",
        "    CLASS = TensorEncoder(), FeaturesSetConfig(shape=7)\n",
        "    VIDEO_FACE_R2PLUS1_FEATURES = TensorEncoder(), FeaturesSetConfig(shape=(33, 512))\n",
        "    VIDEO_SCENE_R2PLUS1_FEATURES = TensorEncoder(), FeaturesSetConfig(shape=(33, 512))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E0IJC_a-gz3h"
      },
      "source": [
        "# Модели"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gv5bv8REg3Jj"
      },
      "source": [
        "def get_r2_plus_1_model(base_path):\n",
        "    return torchvision.models.video.r2plus1d_18(pretrained=True).to(device)\n",
        "\n",
        "def get_l3_model(base_path):\n",
        "    model = tf.keras.models.load_model(base_path + \"/openl3_audio_mel256_env.h5\", custom_objects={\n",
        "        'Melspectrogram': Melspectrogram}, compile=False)\n",
        "\n",
        "    output = model.get_layer('activation_7').output\n",
        "    output = tf.keras.layers.GlobalAveragePooling2D()(output)\n",
        "    intermediate_layer_model = Model(inputs=model.input, outputs=output)\n",
        "    return intermediate_layer_model\n",
        "\n",
        "def get_vgg_model():\n",
        "    return tf.keras.applications.VGG16(include_top=False, weights='imagenet', input_shape=(224, 224, 3))\n",
        "\n",
        "def get_vgg_face_model():\n",
        "    return VGGFace(include_top=False, weights='vggface', input_shape=(224, 224, 3), pooling='avg')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xllfNFUkvPOm"
      },
      "source": [
        "# Утилиты для видео"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-EliF0BDvSAU"
      },
      "source": [
        "def open_video(filename: str, size=224) -> tuple:\n",
        "    cap = cv2.VideoCapture(filename)\n",
        "    if not cap.isOpened():\n",
        "        print(\"[ERROR][TF RECORDS BUILDING][VIDEO FACE] It's impossible to open file '{}'\".format(filename))\n",
        "        cap.release()\n",
        "\n",
        "        filename = os.path.splitext(filename)[0] + \".avi\"\n",
        "        cap = cv2.VideoCapture(filename)\n",
        "        if not cap.isOpened():\n",
        "            cap.release()\n",
        "            print(\"[ERROR][TF RECORDS BUILDING][VIDEO FACE] It's impossible to open file '{}'\".format(filename))\n",
        "            filename = os.path.splitext(filename)[0] + \".mov\"\n",
        "            cap = cv2.VideoCapture(filename)\n",
        "            if not cap.isOpened():\n",
        "                cap.release()\n",
        "                print(\"[ERROR][TF RECORDS BUILDING][VIDEO FACE] It's impossible to open file '{}'\".format(filename))\n",
        "                raise RuntimeError\n",
        "\n",
        "    fps = cap.get(cv2.CAP_PROP_FPS)\n",
        "\n",
        "    example_frames = []\n",
        "    while cap.isOpened():\n",
        "        read, frame = cap.read()\n",
        "        if not read:\n",
        "            break\n",
        "        example_frames.append(cv2.resize(frame, (size, size)))\n",
        "\n",
        "    cap.release()\n",
        "    return example_frames, fps\n",
        "\n",
        "\n",
        "def extract_frames_from_video_with_fps(frames: list, fps, example: str, offset: float, duration: float, modality):\n",
        "    offset_frames_count = math.floor(fps * offset)\n",
        "    extracted_frames_count = math.floor(fps * duration)\n",
        "\n",
        "    source_frames_count = math.floor(modality.config.FPS * duration)\n",
        "    if extracted_frames_count < source_frames_count:\n",
        "        diff = (source_frames_count - extracted_frames_count)\n",
        "        delta = math.floor(diff / 2)\n",
        "        offset_frames_count = math.floor(max(0, offset_frames_count - delta))\n",
        "        extracted_frames_count = math.floor(min(len(frames) - 1, extracted_frames_count + diff))\n",
        "\n",
        "    example_frames_list = frames[offset_frames_count:offset_frames_count + extracted_frames_count]\n",
        "\n",
        "    example_total_frames = len(example_frames_list)\n",
        "\n",
        "    frames_period = math.ceil(example_total_frames / source_frames_count)\n",
        "    period_res = source_frames_count - (math.ceil(example_total_frames / frames_period))\n",
        "\n",
        "    print(\"[INFO][{}] video frames_period:={}, period_res:={}\".format(example, frames_period, period_res))\n",
        "\n",
        "    # to get N frames from the face we extract frames with period and then randomly add\n",
        "    counter_1 = 0\n",
        "    result_list = []\n",
        "    for i in range(example_total_frames):\n",
        "        if frames_period == 1 or i % frames_period == 0:\n",
        "            result_list.append(example_frames_list[i])\n",
        "        elif (i - frames_period // 2) % frames_period == 0 and counter_1 < period_res:\n",
        "            counter_1 += 1\n",
        "            result_list.append(example_frames_list[i])\n",
        "\n",
        "    result_list_resized = []\n",
        "    for frame in result_list:\n",
        "        result_list_resized.append(cv2.resize(frame, (modality.config.SHAPE, modality.config.SHAPE)))\n",
        "\n",
        "    if len(result_list_resized) != source_frames_count:\n",
        "        delta = source_frames_count - len(result_list_resized)\n",
        "        result_list_resized = np.pad(result_list_resized, ((0, delta), (0, 0), (0, 0), (0, 0)), 'constant')\n",
        "\n",
        "    return np.asarray(result_list_resized)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c6ZuRLnKfpq4"
      },
      "source": [
        "# Извлечение признаков"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JRvlOZZqgwyX"
      },
      "source": [
        "def extract_r2_plus1_features(model, frames) -> np.ndarray:\n",
        "    model_input = np.array(list(map(r2_plus_1_preprocess, frames)))\n",
        "    model_input = tf.signal.frame(model_input, 32, 4, axis=0).numpy()\n",
        "    # (1, 8, 3, 112, 112) - >(1, 3, 8, 112, 112)\n",
        "    model_input = np.transpose(model_input, (0, 2, 1, 3, 4)).astype(np.float32)\n",
        "\n",
        "    features = np.array(list(map(lambda x: extract_from_net(model, x), model_input)))\n",
        "    features = np.array(list(map(lambda x: np.squeeze(x), features)))\n",
        "    return features\n",
        "\n",
        "def extract_from_net(model, frames):\n",
        "    frames = np.expand_dims(frames, 0)\n",
        "    input_tensor = torch.Tensor(frames)\n",
        "    input_tensor = input_tensor.to(device)\n",
        "    name = \"avgpool\"\n",
        "    activation = {}\n",
        "    def get_activation(name):\n",
        "        def hook(model, input, output):\n",
        "            activation[name] = output.detach()\n",
        "        return hook\n",
        "    model.avgpool.register_forward_hook(get_activation(name))\n",
        "    model(input_tensor)\n",
        "    features = activation[name].cpu().numpy()\n",
        "    return features\n",
        "\n",
        "\n",
        "def r2_plus_1_preprocess(frame):\n",
        "    resized = cv2.resize(frame, (112, 112))\n",
        "    resized = np.transpose(resized, (2, 0, 1))\n",
        "    return resized\n",
        "\n",
        "\n",
        "def _preprocess_audio_batch(audio, sr, center=True, hop_size=0.5, TARGET_SR=48000):\n",
        "    \"\"\"Process audio into batch format suitable for input to embedding model \"\"\"\n",
        "    if audio.size == 0:\n",
        "        raise RuntimeError('Got empty audio')\n",
        "\n",
        "    # Check audio array dimension\n",
        "    if audio.ndim > 2:\n",
        "        raise RuntimeError('Audio array can only be be 1D or 2D')\n",
        "\n",
        "    elif audio.ndim == 2:\n",
        "        # Downmix if multichannel\n",
        "        audio = np.mean(audio, axis=1)\n",
        "\n",
        "    if not isinstance(sr, Real) or sr <= 0:\n",
        "        raise RuntimeError('Invalid sample rate {}'.format(sr))\n",
        "\n",
        "    if not isinstance(hop_size, Real) or hop_size <= 0:\n",
        "        raise RuntimeError('Invalid hop size {}'.format(hop_size))\n",
        "\n",
        "    if center not in (True, False):\n",
        "        raise RuntimeError('Invalid center value {}'.format(center))\n",
        "\n",
        "    # Resample if necessary\n",
        "    if sr != TARGET_SR:\n",
        "        audio = resampy.resample(audio, sr_orig=sr, sr_new=TARGET_SR, filter='kaiser_best')\n",
        "\n",
        "    audio_len = audio.size\n",
        "    frame_len = TARGET_SR\n",
        "    hop_len = int(hop_size * TARGET_SR)\n",
        "\n",
        "    if center:\n",
        "        # Center audio\n",
        "        audio = _center_audio(audio, frame_len)\n",
        "\n",
        "    # Pad if necessary to ensure that we process all samples\n",
        "    audio = _pad_audio(audio, frame_len, hop_len)\n",
        "\n",
        "    # Split audio into frames, copied from librosa.util.frame\n",
        "    n_frames = 1 + int((len(audio) - frame_len) / float(hop_len))\n",
        "    x = np.lib.stride_tricks.as_strided(audio, shape=(frame_len, n_frames),\n",
        "                                        strides=(audio.itemsize, audio.itemsize)).T\n",
        "\n",
        "    # Add a channel dimension\n",
        "    x = x.reshape((x.shape[0], 1, x.shape[-1]))\n",
        "    return x\n",
        "\n",
        "\n",
        "\n",
        "def _center_audio(audio, frame_len):\n",
        "    \"\"\"Center audio so that first sample will occur in the middle of the first frame\"\"\"\n",
        "    return np.pad(audio, (int(frame_len / 2.0), 0), mode='constant', constant_values=0)\n",
        "\n",
        "\n",
        "def _pad_audio(audio, frame_len, hop_len):\n",
        "    \"\"\"Pad audio if necessary so that all samples are processed\"\"\"\n",
        "    audio_len = audio.size\n",
        "    if audio_len < frame_len:\n",
        "        pad_length = frame_len - audio_len\n",
        "    else:\n",
        "        pad_length = int(np.ceil((audio_len - frame_len) / float(hop_len))) * hop_len \\\n",
        "                     - (audio_len - frame_len)\n",
        "\n",
        "    if pad_length > 0:\n",
        "        audio = np.pad(audio, (0, pad_length), mode='constant', constant_values=0)\n",
        "\n",
        "    return audio\n",
        "\n",
        "\n",
        "def stand(x):\n",
        "    return (x - np.mean(x) / np.std(x))\n",
        "\n",
        "\n",
        "def _extract_opensmile_features(audio, sr, features_set):\n",
        "    smile = opensmile.Smile(\n",
        "        feature_set=features_set,\n",
        "        feature_level=opensmile.FeatureLevel.Functionals,\n",
        "    )\n",
        "\n",
        "    return np.array(list(map(lambda x: stand(smile.process_signal(np.squeeze(x), sr)), audio)))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jg6v0PadyOnX"
      },
      "source": [
        "def extract_l3_features(model, audio) -> np.ndarray:\n",
        "    # model_input = _l3_preprocess_audio(audio, AudioModalityConfig().SR)\n",
        "    return model.predict(audio)\n",
        "\n",
        "\n",
        "def extract_vgg_face_features(model, frames) -> np.ndarray:\n",
        "    return model.predict(frames)\n",
        "\n",
        "def extract_vgg_features(model, frames) -> np.ndarray:\n",
        "    features = model.predict(frames)\n",
        "    return np.reshape(features, (features.shape[0], features.shape[1] * features.shape[2] * features.shape[3]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P4Z7Z_OPD0T3"
      },
      "source": [
        "## Face"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dt539BMIve8n"
      },
      "source": [
        "def _select_face(frame, face, max_face_w, max_face_h):\n",
        "    # increase face window\n",
        "    x = face[0]\n",
        "    y = face[1]\n",
        "    w = max_face_w\n",
        "    h = max_face_h\n",
        "\n",
        "    return frame[y:y + h, x:x + w]\n",
        "\n",
        "\n",
        "def _process_face_on_frame(frame: np.ndarray, face_model):\n",
        "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
        "    faces = face_model.detectMultiScale(gray, 1.1, 4)\n",
        "\n",
        "    if len(faces) == 1:\n",
        "        face = faces[0]\n",
        "        return face\n",
        "    elif len(faces) > 1:\n",
        "        face_size = 0\n",
        "        current_face = faces[0]\n",
        "        nearest_face = None\n",
        "        for face in faces:\n",
        "            current_face_size = current_face[2] * current_face[3]\n",
        "            if current_face_size > face_size:\n",
        "                face_size = current_face_size\n",
        "                nearest_face = face\n",
        "        return nearest_face\n",
        "    else:\n",
        "        return None\n",
        "\n",
        "def extract_face(frames, model):\n",
        "  last_face_coords = None\n",
        "  frames_with_face = []\n",
        "  face_coords = [ _process_face_on_frame(f, model) for f in frames]\n",
        "\n",
        "  max_face_w, max_face_h = -1, -1\n",
        "  for i, face_coord in enumerate(face_coords):\n",
        "    if face_coord is not None and face_coord[2] > max_face_w:\n",
        "      max_face_w = face_coord[2]\n",
        "    if face_coord is not None and face_coord[3] > max_face_h:\n",
        "      max_face_h = face_coord[3]\n",
        "      \n",
        "  for i, face_coord in enumerate(face_coords):\n",
        "    if face_coord is None:\n",
        "      if last_face_coords is not None:\n",
        "        frames_with_face.append(cv2.resize(_select_face(frames[i], last_face_coords, max_face_w, max_face_h), (224, 224)))\n",
        "      else:\n",
        "        frames_with_face.append(cv2.resize(np.zeros(frames[i].shape), (224, 224)))\n",
        "    else:\n",
        "      frames_with_face.append(cv2.resize(_select_face(frames[i], face_coord, max_face_w, max_face_h), (224, 224)))\n",
        "      last_face_coords = face_coord\n",
        "\n",
        "  return np.asarray(frames_with_face).astype('float32')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hmLMul1N3iG1"
      },
      "source": [
        "def extract_face_and_coords_dict(frames, model):\n",
        "  last_face_coords = None\n",
        "  frames_with_face = []\n",
        "  face_coords = [ _process_face_on_frame(f, model) for f in frames]\n",
        "  res = []\n",
        "  last_face = None\n",
        "  for i, face_coords in enumerate(face_coords):\n",
        "    if face_coords is not None:\n",
        "      res.append(face_coords)\n",
        "      last_face = face_coords\n",
        "    elif last_face is not None:\n",
        "      res.append(last_face)\n",
        "    else:\n",
        "      res.append([0,0,frames[i].shape[0], frames[i].shape[1]])\n",
        "\n",
        "  return np.asarray(frames), np.asarray(res)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-BhE1bM_D2GI"
      },
      "source": [
        "## Pulse"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "02ONlxQTD32g"
      },
      "source": [
        "from utils.pulse_detection.processors_noopenmdao import findFaceGetPulse\n",
        "\n",
        "class PulseDetector():\n",
        "    flagTest = True\n",
        "    var = 0\n",
        "    mean = 0\n",
        "\n",
        "\n",
        "    def __init__(self):\n",
        "        self.processor = findFaceGetPulse(bpm_limits=[50, 180],\n",
        "                                          data_spike_limit=2500.,\n",
        "                                          face_detector_smoothness=10.0)\n",
        "\n",
        "\n",
        "    def toggle_search(self):\n",
        "        \"\"\"\n",
        "        Toggles a motion lock on the processor's face detection component.\n",
        "        Locking the forehead location in place significantly improves\n",
        "        data quality, once a forehead has been sucessfully isolated.\n",
        "        \"\"\"\n",
        "        state = self.processor.find_faces_toggle()\n",
        "\n",
        "    def main_loop(self, i, frame, coords):\n",
        "    \n",
        "        \"\"\"\n",
        "        Single iteration of the application's main loop.\n",
        "        \"\"\"\n",
        "        img = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
        "        _,thresh = cv2.threshold(img,10,255,cv2.THRESH_BINARY)\n",
        "        contours,hierarchy = cv2.findContours(thresh,cv2.RETR_EXTERNAL,cv2.CHAIN_APPROX_SIMPLE)\n",
        "        if (len(contours) == 0): \n",
        "          return\n",
        "        cnt = contours[0]\n",
        "        x,y,w,h = cv2.boundingRect(cnt)\n",
        "        offset_y = 0\n",
        "        offset_x = 0\n",
        "        self.h, self.w, _c = frame.shape\n",
        "\n",
        "        # set current image frame to the processor's input\n",
        "        self.processor.frame_in = frame\n",
        "        self.processor.coords = [coords]\n",
        "#         # process the image frame to perform all needed analysis\n",
        "        self.processor.run('')\n",
        "#         # collect the output frame for display\n",
        "        output_frame = self.processor.frame_out\n",
        "        \n",
        "        if self.flagTest is True and i > 10:\n",
        "            self.toggle_search()\n",
        "            self.flagTest = False\n",
        "        \n",
        "        if (i % 80 == 0 or i % 81 == 0) and i > 10:\n",
        "            self.toggle_search()\n",
        "            self.flagTest = False\n",
        "        self.var = np.var(self.processor.bpms)\n",
        "        self.mean = np.mean(self.processor.bpms)\n",
        "\n",
        "\n",
        "def get_pulse(frames, coords):\n",
        "    frames = tf.signal.frame(frames, 25, 1, axis=0).numpy()\n",
        "    coords = tf.signal.frame(coords, 25, 1, axis=0).numpy()\n",
        "\n",
        "    result = []\n",
        "    for i in range(len(frames)):\n",
        "      result.append(get_pulse_from_window(frames[i], coords[i]))\n",
        "    return np.array(result)\n",
        "\n",
        "\n",
        "def get_pulse_from_window(frames, coords):\n",
        "  pulse_detector = PulseDetector()\n",
        "  for i, frame in enumerate(frames):\n",
        "    pulse_detector.main_loop(i, frame, coords[i])\n",
        "  res = np.asarray([pulse_detector.var, pulse_detector.mean]).astype(np.float32)\n",
        "  del pulse_detector\n",
        "  return res"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ypa0v0XgZywO"
      },
      "source": [
        "# Обработка"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o1Zl3Kf9oCpR"
      },
      "source": [
        "WINDOW_LEN_IN_SEC = 10\n",
        "STEP_LEN_IN_SEC = 1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1IxynukmoDey",
        "outputId": "2b6d39d6-fe9f-48f7-f86b-709e99246632"
      },
      "source": [
        "r2_plus_1_model = get_r2_plus_1_model(PRETRAINED_MODELS)\n",
        "\n",
        "with tf.device('/device:GPU:0'):\n",
        "  l3_model = get_l3_model(PRETRAINED_MODELS)\n",
        "  vgg_model = get_vgg_model()\n",
        "  vgg_face_model = get_vgg_face_model()\n",
        "\n",
        "face_model = cv2.CascadeClassifier('/content/lieDetector/utils/pulse_detection/haarcascade_frontalface_alt.xml')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/librosa/filters.py:239: UserWarning: Empty filters detected in mel frequency basis. Some channels will produce empty responses. Try increasing your sampling rate (and fmax) or reducing n_mels.\n",
            "  \"Empty filters detected in mel frequency basis. \"\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JACykwPNSKNW"
      },
      "source": [
        "def _process_audio_modality(filename: str, offset: float, duration: float, modality) -> dict:\n",
        "    features_by_name = {}\n",
        "    audio_raw, audio_raw_rate = lb.load(filename, offset=offset, duration=duration, sr=48000)\n",
        "    audio = _apply_window_to_signal(audio_raw, 48000, WINDOW_LEN_IN_SEC, STEP_LEN_IN_SEC)\n",
        "    features_by_name[DatasetFeaturesSet.AUDIO] = audio\n",
        "    print(f\"[INFO][{filename}][Audio] Complete audio: shape:={features_by_name[DatasetFeaturesSet.AUDIO].shape}\")\n",
        "    return features_by_name\n",
        "\n",
        "\n",
        "def _process_video_scene_modality(frames: list, fps, example: str, offset: float, duration: float,\n",
        "                                  modality) -> dict:\n",
        "    print(f\"[INFO][{example}] Preprocess video input\")\n",
        "    sparse_frames = extract_frames_from_video_with_fps(frames, fps, example, offset, duration, modality)\n",
        "    sparse_frames = _apply_window_to_signal(sparse_frames, modality.config.FPS, WINDOW_LEN_IN_SEC, STEP_LEN_IN_SEC)\n",
        "    return {\n",
        "        DatasetFeaturesSet.VIDEO_FACE: sparse_frames\n",
        "    }\n",
        "\n",
        "\n",
        "def _process_video_face_modality(frames: list, fps, example: str, offset: float, duration: float,\n",
        "                                 modality) -> dict:\n",
        "    print(f\"[INFO][{example}] Preprocess video face input\")\n",
        "    sparse_frames = extract_frames_from_video_with_fps(frames, fps, example, offset, duration, modality)\n",
        "    sparse_frames = extract_face(sparse_frames, face_model)\n",
        "    sparse_frames = _apply_window_to_signal(sparse_frames, modality.config.FPS, WINDOW_LEN_IN_SEC, STEP_LEN_IN_SEC)\n",
        "    return {\n",
        "        DatasetFeaturesSet.VIDEO_SCENE: sparse_frames\n",
        "    }\n",
        "\n",
        "\n",
        "def _process_pulse_modality(frames: list, fps, example: str, offset: float, duration: float,\n",
        "                            modality) -> dict:\n",
        "    print(f\"[INFO][{example}] Preprocess pulse input\")\n",
        "    sparse_frames = extract_frames_from_video_with_fps(frames, fps, example, offset, duration, modality)\n",
        "    sparse_frames, coords = extract_face_and_coords_dict(sparse_frames, face_model)\n",
        "    sparse_frames = _apply_window_to_signal(sparse_frames, modality.config.FPS, WINDOW_LEN_IN_SEC, STEP_LEN_IN_SEC)\n",
        "    coords = _apply_window_to_signal(coords, modality.config.FPS, WINDOW_LEN_IN_SEC, STEP_LEN_IN_SEC)\n",
        "\n",
        "    return {\n",
        "        DatasetFeaturesSet.PULSE: sparse_frames,\n",
        "        'coords': coords\n",
        "    }\n",
        "\n",
        "\n",
        "def _apply_window_to_signal(signal, elements_per_sec, window_len_sec, step_len_sec) -> np.ndarray:\n",
        "    min_allowed_elements = window_len_sec * elements_per_sec\n",
        "\n",
        "    if signal.shape[0] < min_allowed_elements:\n",
        "        pad = np.zeros((len(signal.shape), 2), dtype=int)\n",
        "        pad[0][1] = min_allowed_elements - signal.shape[0]\n",
        "        signal = np.pad(signal.astype(np.float32), pad, 'constant')\n",
        "    return tf.signal.frame(signal, elements_per_sec * window_len_sec, elements_per_sec * step_len_sec, axis=0).numpy()\n",
        "\n",
        "\n",
        "def _extract_features_from_data(filename, data_from_window) -> dict:\n",
        "    with tf.device('/device:GPU:0'):\n",
        "        features_by_name = {}\n",
        "\n",
        "        # Face\n",
        "        print(f'[{filename}] Extracting features ...')\n",
        "        features_by_name[DatasetFeaturesSet.VIDEO_FACE] = extract_vgg_face_features(vgg_face_model, data_from_window[DatasetFeaturesSet.VIDEO_FACE])\n",
        "        print(f'[{filename}] Extracting vgg face: shape:={features_by_name[DatasetFeaturesSet.VIDEO_FACE].shape}')\n",
        "\n",
        "        # Scene\n",
        "        scene_features_r2 = extract_r2_plus1_features(r2_plus_1_model,\n",
        "                                                      data_from_window[DatasetFeaturesSet.VIDEO_SCENE])\n",
        "        print(f'[{filename}] Extracting r2_plus1_features features: shape:={scene_features_r2.shape}')\n",
        "        features_by_name[DatasetFeaturesSet.VIDEO_SCENE_R2PLUS1_FEATURES] = scene_features_r2\n",
        "\n",
        "        features_by_name[DatasetFeaturesSet.VIDEO_SCENE] = extract_vgg_features(vgg_model, data_from_window[DatasetFeaturesSet.VIDEO_SCENE])\n",
        "        print(f'[{filename}] Extracting scene features: shape:={features_by_name[DatasetFeaturesSet.VIDEO_SCENE].shape}')\n",
        "\n",
        "        # Audio\n",
        "        preprocessed_audio = _preprocess_audio_batch(data_from_window[DatasetFeaturesSet.AUDIO], 48000)\n",
        "        features_by_name[DatasetFeaturesSet.AUDIO] = extract_l3_features(l3_model, preprocessed_audio)\n",
        "        print(f'[{filename}] Extracting audio l3 features: shape:={features_by_name[DatasetFeaturesSet.AUDIO].shape}')\n",
        "\n",
        "        pulse_features = get_pulse(data_from_window[DatasetFeaturesSet.PULSE], data_from_window['coords'])\n",
        "        print(f'[{filename}] Extracting pulse_features features: shape:={pulse_features.shape}')\n",
        "        features_by_name[DatasetFeaturesSet.PULSE] = np.expand_dims(np.nan_to_num(pulse_features).astype(np.float32), -1)\n",
        "\n",
        "    return features_by_name\n",
        "\n",
        "\n",
        "def _encode_example(features_by_name, clazz):\n",
        "    tf_features_dict = {}\n",
        "    for modality, feature in features_by_name.items():\n",
        "        tf_features_dict[str(modality.name)] = modality.encoder.transform(feature.astype(np.float32))\n",
        "\n",
        "    tf_features_dict[DatasetFeaturesSet.CLASS.name] = DatasetFeaturesSet.CLASS.encoder.transform(\n",
        "        clazz.astype(np.float32))\n",
        "\n",
        "    example = tf.train.Example(features=tf.train.Features(feature=tf_features_dict))\n",
        "    return example.SerializeToString()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tju2OMk_88N3"
      },
      "source": [
        "audio_file_path  = '/content/drive/MyDrive/garold.wav'\n",
        "video_file_path  = '/content/drive/MyDrive/garold.mp4'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A65fE-Hx6NLY",
        "outputId": "5d15e508-e450-4d4b-93d3-cb770f2fc555"
      },
      "source": [
        "features = []\n",
        "offset = 0\n",
        "video_frames, video_fps = None, 0\n",
        "\n",
        "\n",
        "data_by_window = {}\n",
        "\n",
        "duration = 30\n",
        "video_frames, video_fps = open_video(video_file_path)\n",
        "video_frames = np.asarray(video_frames)[int(video_fps * 25):int(video_fps * 55),]\n",
        "print(video_frames.shape)\n",
        "data_by_window.update(_process_audio_modality(audio_file_path, offset, duration, Modality.AUDIO))\n",
        "data_by_window.update(_process_video_scene_modality(video_frames, video_fps,\n",
        "                                                    video_file_path, offset,\n",
        "                                                    duration, Modality.VIDEO_SCENE))\n",
        "data_by_window.update(_process_video_face_modality(video_frames, video_fps,\n",
        "                                                   video_file_path, offset,\n",
        "                                                   duration, Modality.VIDEO_FACE))\n",
        "data_by_window.update(_process_pulse_modality(video_frames, video_fps,\n",
        "                                              video_file_path, offset,\n",
        "                                              duration, Modality.PULSE))\n",
        "\n",
        "windows_of_data = [dict(zip(data_by_window, t)) for t in zip(*data_by_window.values())]\n",
        "for i, data_from_window in enumerate(windows_of_data):\n",
        "    print(f'[{video_file_path}] Saving window position... #{i}')\n",
        "    features_dict = _extract_features_from_data(video_file_path, data_from_window)\n",
        "    features.append(features_dict)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(750, 224, 224, 3)\n",
            "[INFO][/content/drive/MyDrive/garold.wav][Audio] Complete audio: shape:=(21, 480000)\n",
            "[INFO][/content/drive/MyDrive/garold.mp4] Preprocess video input\n",
            "[INFO][/content/drive/MyDrive/garold.mp4] video frames_period:=1, period_res:=211\n",
            "[INFO][/content/drive/MyDrive/garold.mp4] Preprocess video face input\n",
            "[INFO][/content/drive/MyDrive/garold.mp4] video frames_period:=1, period_res:=211\n",
            "[INFO][/content/drive/MyDrive/garold.mp4] Preprocess pulse input\n",
            "[INFO][/content/drive/MyDrive/garold.mp4] video frames_period:=1, period_res:=751\n",
            "[/content/drive/MyDrive/garold.mp4] Saving window position... #0\n",
            "[/content/drive/MyDrive/garold.mp4] Extracting features ...\n",
            "[/content/drive/MyDrive/garold.mp4] Extracting vgg face: shape:=(320, 512)\n",
            "[/content/drive/MyDrive/garold.mp4] Extracting r2_plus1_features features: shape:=(73, 512)\n",
            "[/content/drive/MyDrive/garold.mp4] Extracting scene features: shape:=(320, 25088)\n",
            "[/content/drive/MyDrive/garold.mp4] Extracting audio l3 features: shape:=(20, 512)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/numpy/core/fromnumeric.py:3622: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
            "  **kwargs)\n",
            "/usr/local/lib/python3.7/dist-packages/numpy/core/_methods.py:195: RuntimeWarning: invalid value encountered in true_divide\n",
            "  arrmean, rcount, out=arrmean, casting='unsafe', subok=False)\n",
            "/usr/local/lib/python3.7/dist-packages/numpy/core/_methods.py:226: RuntimeWarning: invalid value encountered in double_scalars\n",
            "  ret = ret.dtype.type(ret / rcount)\n",
            "/usr/local/lib/python3.7/dist-packages/numpy/core/fromnumeric.py:3373: RuntimeWarning: Mean of empty slice.\n",
            "  out=out, **kwargs)\n",
            "/usr/local/lib/python3.7/dist-packages/numpy/core/_methods.py:170: RuntimeWarning: invalid value encountered in double_scalars\n",
            "  ret = ret.dtype.type(ret / rcount)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[/content/drive/MyDrive/garold.mp4] Extracting pulse_features features: shape:=(476, 2)\n",
            "[/content/drive/MyDrive/garold.mp4] Saving window position... #1\n",
            "[/content/drive/MyDrive/garold.mp4] Extracting features ...\n",
            "[/content/drive/MyDrive/garold.mp4] Extracting vgg face: shape:=(320, 512)\n",
            "[/content/drive/MyDrive/garold.mp4] Extracting r2_plus1_features features: shape:=(73, 512)\n",
            "[/content/drive/MyDrive/garold.mp4] Extracting scene features: shape:=(320, 25088)\n",
            "[/content/drive/MyDrive/garold.mp4] Extracting audio l3 features: shape:=(20, 512)\n",
            "[/content/drive/MyDrive/garold.mp4] Extracting pulse_features features: shape:=(476, 2)\n",
            "[/content/drive/MyDrive/garold.mp4] Saving window position... #2\n",
            "[/content/drive/MyDrive/garold.mp4] Extracting features ...\n",
            "[/content/drive/MyDrive/garold.mp4] Extracting vgg face: shape:=(320, 512)\n",
            "[/content/drive/MyDrive/garold.mp4] Extracting r2_plus1_features features: shape:=(73, 512)\n",
            "[/content/drive/MyDrive/garold.mp4] Extracting scene features: shape:=(320, 25088)\n",
            "[/content/drive/MyDrive/garold.mp4] Extracting audio l3 features: shape:=(20, 512)\n",
            "[/content/drive/MyDrive/garold.mp4] Extracting pulse_features features: shape:=(476, 2)\n",
            "[/content/drive/MyDrive/garold.mp4] Saving window position... #3\n",
            "[/content/drive/MyDrive/garold.mp4] Extracting features ...\n",
            "[/content/drive/MyDrive/garold.mp4] Extracting vgg face: shape:=(320, 512)\n",
            "[/content/drive/MyDrive/garold.mp4] Extracting r2_plus1_features features: shape:=(73, 512)\n",
            "[/content/drive/MyDrive/garold.mp4] Extracting scene features: shape:=(320, 25088)\n",
            "[/content/drive/MyDrive/garold.mp4] Extracting audio l3 features: shape:=(20, 512)\n",
            "[/content/drive/MyDrive/garold.mp4] Extracting pulse_features features: shape:=(476, 2)\n",
            "[/content/drive/MyDrive/garold.mp4] Saving window position... #4\n",
            "[/content/drive/MyDrive/garold.mp4] Extracting features ...\n",
            "[/content/drive/MyDrive/garold.mp4] Extracting vgg face: shape:=(320, 512)\n",
            "[/content/drive/MyDrive/garold.mp4] Extracting r2_plus1_features features: shape:=(73, 512)\n",
            "[/content/drive/MyDrive/garold.mp4] Extracting scene features: shape:=(320, 25088)\n",
            "[/content/drive/MyDrive/garold.mp4] Extracting audio l3 features: shape:=(20, 512)\n",
            "[/content/drive/MyDrive/garold.mp4] Extracting pulse_features features: shape:=(476, 2)\n",
            "[/content/drive/MyDrive/garold.mp4] Saving window position... #5\n",
            "[/content/drive/MyDrive/garold.mp4] Extracting features ...\n",
            "[/content/drive/MyDrive/garold.mp4] Extracting vgg face: shape:=(320, 512)\n",
            "[/content/drive/MyDrive/garold.mp4] Extracting r2_plus1_features features: shape:=(73, 512)\n",
            "[/content/drive/MyDrive/garold.mp4] Extracting scene features: shape:=(320, 25088)\n",
            "[/content/drive/MyDrive/garold.mp4] Extracting audio l3 features: shape:=(20, 512)\n",
            "[/content/drive/MyDrive/garold.mp4] Extracting pulse_features features: shape:=(476, 2)\n",
            "[/content/drive/MyDrive/garold.mp4] Saving window position... #6\n",
            "[/content/drive/MyDrive/garold.mp4] Extracting features ...\n",
            "[/content/drive/MyDrive/garold.mp4] Extracting vgg face: shape:=(320, 512)\n",
            "[/content/drive/MyDrive/garold.mp4] Extracting r2_plus1_features features: shape:=(73, 512)\n",
            "[/content/drive/MyDrive/garold.mp4] Extracting scene features: shape:=(320, 25088)\n",
            "[/content/drive/MyDrive/garold.mp4] Extracting audio l3 features: shape:=(20, 512)\n",
            "[/content/drive/MyDrive/garold.mp4] Extracting pulse_features features: shape:=(476, 2)\n",
            "[/content/drive/MyDrive/garold.mp4] Saving window position... #7\n",
            "[/content/drive/MyDrive/garold.mp4] Extracting features ...\n",
            "[/content/drive/MyDrive/garold.mp4] Extracting vgg face: shape:=(320, 512)\n",
            "[/content/drive/MyDrive/garold.mp4] Extracting r2_plus1_features features: shape:=(73, 512)\n",
            "[/content/drive/MyDrive/garold.mp4] Extracting scene features: shape:=(320, 25088)\n",
            "[/content/drive/MyDrive/garold.mp4] Extracting audio l3 features: shape:=(20, 512)\n",
            "[/content/drive/MyDrive/garold.mp4] Extracting pulse_features features: shape:=(476, 2)\n",
            "[/content/drive/MyDrive/garold.mp4] Saving window position... #8\n",
            "[/content/drive/MyDrive/garold.mp4] Extracting features ...\n",
            "[/content/drive/MyDrive/garold.mp4] Extracting vgg face: shape:=(320, 512)\n",
            "[/content/drive/MyDrive/garold.mp4] Extracting r2_plus1_features features: shape:=(73, 512)\n",
            "[/content/drive/MyDrive/garold.mp4] Extracting scene features: shape:=(320, 25088)\n",
            "[/content/drive/MyDrive/garold.mp4] Extracting audio l3 features: shape:=(20, 512)\n",
            "[/content/drive/MyDrive/garold.mp4] Extracting pulse_features features: shape:=(476, 2)\n",
            "[/content/drive/MyDrive/garold.mp4] Saving window position... #9\n",
            "[/content/drive/MyDrive/garold.mp4] Extracting features ...\n",
            "[/content/drive/MyDrive/garold.mp4] Extracting vgg face: shape:=(320, 512)\n",
            "[/content/drive/MyDrive/garold.mp4] Extracting r2_plus1_features features: shape:=(73, 512)\n",
            "[/content/drive/MyDrive/garold.mp4] Extracting scene features: shape:=(320, 25088)\n",
            "[/content/drive/MyDrive/garold.mp4] Extracting audio l3 features: shape:=(20, 512)\n",
            "[/content/drive/MyDrive/garold.mp4] Extracting pulse_features features: shape:=(476, 2)\n",
            "[/content/drive/MyDrive/garold.mp4] Saving window position... #10\n",
            "[/content/drive/MyDrive/garold.mp4] Extracting features ...\n",
            "[/content/drive/MyDrive/garold.mp4] Extracting vgg face: shape:=(320, 512)\n",
            "[/content/drive/MyDrive/garold.mp4] Extracting r2_plus1_features features: shape:=(73, 512)\n",
            "[/content/drive/MyDrive/garold.mp4] Extracting scene features: shape:=(320, 25088)\n",
            "[/content/drive/MyDrive/garold.mp4] Extracting audio l3 features: shape:=(20, 512)\n",
            "[/content/drive/MyDrive/garold.mp4] Extracting pulse_features features: shape:=(476, 2)\n",
            "[/content/drive/MyDrive/garold.mp4] Saving window position... #11\n",
            "[/content/drive/MyDrive/garold.mp4] Extracting features ...\n",
            "[/content/drive/MyDrive/garold.mp4] Extracting vgg face: shape:=(320, 512)\n",
            "[/content/drive/MyDrive/garold.mp4] Extracting r2_plus1_features features: shape:=(73, 512)\n",
            "[/content/drive/MyDrive/garold.mp4] Extracting scene features: shape:=(320, 25088)\n",
            "[/content/drive/MyDrive/garold.mp4] Extracting audio l3 features: shape:=(20, 512)\n",
            "[/content/drive/MyDrive/garold.mp4] Extracting pulse_features features: shape:=(476, 2)\n",
            "[/content/drive/MyDrive/garold.mp4] Saving window position... #12\n",
            "[/content/drive/MyDrive/garold.mp4] Extracting features ...\n",
            "[/content/drive/MyDrive/garold.mp4] Extracting vgg face: shape:=(320, 512)\n",
            "[/content/drive/MyDrive/garold.mp4] Extracting r2_plus1_features features: shape:=(73, 512)\n",
            "[/content/drive/MyDrive/garold.mp4] Extracting scene features: shape:=(320, 25088)\n",
            "[/content/drive/MyDrive/garold.mp4] Extracting audio l3 features: shape:=(20, 512)\n",
            "[/content/drive/MyDrive/garold.mp4] Extracting pulse_features features: shape:=(476, 2)\n",
            "[/content/drive/MyDrive/garold.mp4] Saving window position... #13\n",
            "[/content/drive/MyDrive/garold.mp4] Extracting features ...\n",
            "[/content/drive/MyDrive/garold.mp4] Extracting vgg face: shape:=(320, 512)\n",
            "[/content/drive/MyDrive/garold.mp4] Extracting r2_plus1_features features: shape:=(73, 512)\n",
            "[/content/drive/MyDrive/garold.mp4] Extracting scene features: shape:=(320, 25088)\n",
            "[/content/drive/MyDrive/garold.mp4] Extracting audio l3 features: shape:=(20, 512)\n",
            "[/content/drive/MyDrive/garold.mp4] Extracting pulse_features features: shape:=(476, 2)\n",
            "[/content/drive/MyDrive/garold.mp4] Saving window position... #14\n",
            "[/content/drive/MyDrive/garold.mp4] Extracting features ...\n",
            "[/content/drive/MyDrive/garold.mp4] Extracting vgg face: shape:=(320, 512)\n",
            "[/content/drive/MyDrive/garold.mp4] Extracting r2_plus1_features features: shape:=(73, 512)\n",
            "[/content/drive/MyDrive/garold.mp4] Extracting scene features: shape:=(320, 25088)\n",
            "[/content/drive/MyDrive/garold.mp4] Extracting audio l3 features: shape:=(20, 512)\n",
            "[/content/drive/MyDrive/garold.mp4] Extracting pulse_features features: shape:=(476, 2)\n",
            "[/content/drive/MyDrive/garold.mp4] Saving window position... #15\n",
            "[/content/drive/MyDrive/garold.mp4] Extracting features ...\n",
            "[/content/drive/MyDrive/garold.mp4] Extracting vgg face: shape:=(320, 512)\n",
            "[/content/drive/MyDrive/garold.mp4] Extracting r2_plus1_features features: shape:=(73, 512)\n",
            "[/content/drive/MyDrive/garold.mp4] Extracting scene features: shape:=(320, 25088)\n",
            "[/content/drive/MyDrive/garold.mp4] Extracting audio l3 features: shape:=(20, 512)\n",
            "[/content/drive/MyDrive/garold.mp4] Extracting pulse_features features: shape:=(476, 2)\n",
            "[/content/drive/MyDrive/garold.mp4] Saving window position... #16\n",
            "[/content/drive/MyDrive/garold.mp4] Extracting features ...\n",
            "[/content/drive/MyDrive/garold.mp4] Extracting vgg face: shape:=(320, 512)\n",
            "[/content/drive/MyDrive/garold.mp4] Extracting r2_plus1_features features: shape:=(73, 512)\n",
            "[/content/drive/MyDrive/garold.mp4] Extracting scene features: shape:=(320, 25088)\n",
            "[/content/drive/MyDrive/garold.mp4] Extracting audio l3 features: shape:=(20, 512)\n",
            "[/content/drive/MyDrive/garold.mp4] Extracting pulse_features features: shape:=(476, 2)\n",
            "[/content/drive/MyDrive/garold.mp4] Saving window position... #17\n",
            "[/content/drive/MyDrive/garold.mp4] Extracting features ...\n",
            "[/content/drive/MyDrive/garold.mp4] Extracting vgg face: shape:=(320, 512)\n",
            "[/content/drive/MyDrive/garold.mp4] Extracting r2_plus1_features features: shape:=(73, 512)\n",
            "[/content/drive/MyDrive/garold.mp4] Extracting scene features: shape:=(320, 25088)\n",
            "[/content/drive/MyDrive/garold.mp4] Extracting audio l3 features: shape:=(20, 512)\n",
            "[/content/drive/MyDrive/garold.mp4] Extracting pulse_features features: shape:=(476, 2)\n",
            "[/content/drive/MyDrive/garold.mp4] Saving window position... #18\n",
            "[/content/drive/MyDrive/garold.mp4] Extracting features ...\n",
            "[/content/drive/MyDrive/garold.mp4] Extracting vgg face: shape:=(320, 512)\n",
            "[/content/drive/MyDrive/garold.mp4] Extracting r2_plus1_features features: shape:=(73, 512)\n",
            "[/content/drive/MyDrive/garold.mp4] Extracting scene features: shape:=(320, 25088)\n",
            "[/content/drive/MyDrive/garold.mp4] Extracting audio l3 features: shape:=(20, 512)\n",
            "[/content/drive/MyDrive/garold.mp4] Extracting pulse_features features: shape:=(476, 2)\n",
            "[/content/drive/MyDrive/garold.mp4] Saving window position... #19\n",
            "[/content/drive/MyDrive/garold.mp4] Extracting features ...\n",
            "[/content/drive/MyDrive/garold.mp4] Extracting vgg face: shape:=(320, 512)\n",
            "[/content/drive/MyDrive/garold.mp4] Extracting r2_plus1_features features: shape:=(73, 512)\n",
            "[/content/drive/MyDrive/garold.mp4] Extracting scene features: shape:=(320, 25088)\n",
            "[/content/drive/MyDrive/garold.mp4] Extracting audio l3 features: shape:=(20, 512)\n",
            "[/content/drive/MyDrive/garold.mp4] Extracting pulse_features features: shape:=(476, 2)\n",
            "[/content/drive/MyDrive/garold.mp4] Saving window position... #20\n",
            "[/content/drive/MyDrive/garold.mp4] Extracting features ...\n",
            "[/content/drive/MyDrive/garold.mp4] Extracting vgg face: shape:=(320, 512)\n",
            "[/content/drive/MyDrive/garold.mp4] Extracting r2_plus1_features features: shape:=(73, 512)\n",
            "[/content/drive/MyDrive/garold.mp4] Extracting scene features: shape:=(320, 25088)\n",
            "[/content/drive/MyDrive/garold.mp4] Extracting audio l3 features: shape:=(20, 512)\n",
            "[/content/drive/MyDrive/garold.mp4] Extracting pulse_features features: shape:=(476, 2)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VY1gRadFdwuc"
      },
      "source": [
        "CHECKPOINT_NAME = \"cp-{epoch:04d}.ckpt\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R0LxeWUGwayf"
      },
      "source": [
        "## Предсказание"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g4WVHXaofZML"
      },
      "source": [
        "from kapre.time_frequency import Melspectrogram\n",
        "from keras_vggface import VGGFace\n",
        "\n",
        "from base.base_model import BaseModel\n",
        "import tensorflow as tf\n",
        "\n",
        "from configs.dataset.modality import DatasetFeaturesSet\n",
        "from models.layers.fusion.concatenation_fusion_layer import ConcatenationFusionLayer\n",
        "from models.layers.fusion.fbr_fusion_layer import FactorizedPoolingFusionLayer\n",
        "from models.layers.fusion.sum_fusion_layer import SumFusionLayer\n",
        "\n",
        "\n",
        "class MultimodalModel(BaseModel):\n",
        "\n",
        "    def __init__(self,\n",
        "                 modalities_list,\n",
        "                 fc_units,\n",
        "                 first_layer,\n",
        "                 second_layer,\n",
        "                 cp_dir: str,\n",
        "                 cp_name: str,\n",
        "                 fusion_type='sum',\n",
        "                 dropout=0.1,\n",
        "                 log_and_save_freq_batch: int = 100,\n",
        "                 learning_rate: float = 0.001,\n",
        "                 trained: bool = False):\n",
        "\n",
        "        self._modalities_list = modalities_list\n",
        "        self._learning_rate = learning_rate\n",
        "\n",
        "        self._optimizer = tf.keras.optimizers.Adam\n",
        "\n",
        "        self._lstm_units_first_layer = first_layer\n",
        "        self._lstm_units_second_layer = second_layer\n",
        "        self._activation = 'relu'\n",
        "        self._fc_units = fc_units\n",
        "        self._dropout = dropout\n",
        "        self._pooling_size = 4\n",
        "        self.train_model, self.test_model = self._build_model(fusion_type)\n",
        "        self.model = self.test_model if trained else self.train_model\n",
        "\n",
        "        super(MultimodalModel, self).__init__(cp_dir=cp_dir,\n",
        "                                              cp_name=cp_name,\n",
        "                                              save_freq=log_and_save_freq_batch,\n",
        "                                              model=self.model)\n",
        "\n",
        "    def _build_model(self, fusion_type):\n",
        "        if fusion_type == 'sum':\n",
        "            return self._build_sum_fusion_model()\n",
        "        if fusion_type == 'concatenation':\n",
        "            return self._build_concatenation_fusion_model()\n",
        "        elif fusion_type == 'fbp':\n",
        "            return self._build_fbp_fusion_model()\n",
        "\n",
        "    def _build_sum_fusion_model(self):\n",
        "        inputs = self._build_multimodal_input()\n",
        "        intra_modality_features = []\n",
        "        for i, modality in enumerate(self._modalities_list):\n",
        "            if modality == DatasetFeaturesSet.PULSE:\n",
        "                intra_modality_features.append(self.pulse_conv_net(inputs[i]))\n",
        "            else:\n",
        "                intra_modality_features.append(inputs[i])\n",
        "        intra_modality_outputs = self._build_LSTM_block(intra_modality_features)\n",
        "        fusion_output = SumFusionLayer()(intra_modality_outputs)\n",
        "        output_tensor = self._build_classification_layer(fusion_output)\n",
        "\n",
        "        model = tf.keras.Model(inputs=inputs, outputs=output_tensor)\n",
        "        model.summary()\n",
        "        return model, model\n",
        "\n",
        "    def _build_concatenation_fusion_model(self):\n",
        "        inputs = self._build_multimodal_input()\n",
        "        intra_modality_features = []\n",
        "        for i, modality in enumerate(self._modalities_list):\n",
        "            if modality == DatasetFeaturesSet.PULSE:\n",
        "                intra_modality_features.append(self.pulse_conv_net(inputs[i]))\n",
        "            else:\n",
        "                intra_modality_features.append(inputs[i])\n",
        "        intra_modality_outputs = self._build_LSTM_block(intra_modality_features)\n",
        "        fusion_output = ConcatenationFusionLayer(self._lstm_units_second_layer, len(self._modalities_list))(\n",
        "            intra_modality_outputs)\n",
        "        output_tensor = self._build_classification_layer(fusion_output)\n",
        "\n",
        "        model = tf.keras.Model(inputs=inputs, outputs=output_tensor)\n",
        "        model.summary()\n",
        "        return model, model\n",
        "\n",
        "    def _build_fbp_fusion_model(self):\n",
        "        inputs = self._build_multimodal_input()\n",
        "        print(inputs)\n",
        "        intra_modality_features = []\n",
        "        for i, modality in enumerate(self._modalities_list):\n",
        "            if modality == DatasetFeaturesSet.PULSE:\n",
        "                intra_modality_features.append(self.pulse_conv_net(inputs[i]))\n",
        "            else:\n",
        "                intra_modality_features.append(inputs[i])\n",
        "        intra_modality_outputs = self._build_LSTM_block(intra_modality_features)\n",
        "        fusion_output = FactorizedPoolingFusionLayer(self._dropout, self._pooling_size)(intra_modality_outputs)\n",
        "        output_tensor = self._build_classification_layer(fusion_output)\n",
        "\n",
        "        model = tf.keras.Model(inputs=inputs, outputs=output_tensor)\n",
        "        model.summary()\n",
        "        return model, model\n",
        "\n",
        "    def get_train_model(self):\n",
        "        metrics = ['accuracy', tf.keras.metrics.Precision(), tf.keras.metrics.Recall(),\n",
        "                   tf.keras.metrics.AUC()]\n",
        "        self.train_model.compile(\n",
        "            optimizer=self._optimizer(learning_rate=self._learning_rate),\n",
        "            loss=tf.keras.losses.BinaryCrossentropy(),\n",
        "            metrics=metrics\n",
        "        )\n",
        "        return self.train_model\n",
        "\n",
        "    def get_test_model(self):\n",
        "        return self.test_model\n",
        "\n",
        "    def apply_lstm(self, x):\n",
        "        x = tf.keras.layers.LSTM(units=self._lstm_units_first_layer, return_sequences=True)(x)\n",
        "        x = tf.keras.layers.LSTM(units=self._lstm_units_second_layer)(x)\n",
        "        return x\n",
        "\n",
        "    def pulse_conv_net(self, input_tensor):\n",
        "        x = tf.keras.layers.Conv2D(16,\n",
        "                                   kernel_size=(input_tensor.shape[1] // 2, 2),\n",
        "                                   strides=(2, 1),\n",
        "                                   activation=self._activation)(input_tensor)\n",
        "        x = tf.keras.layers.MaxPool2D(pool_size=(2, 1))(x)\n",
        "        x = tf.keras.layers.Reshape((x.shape[1], 16))(x)\n",
        "        return x\n",
        "\n",
        "    def _build_multimodal_input(self):\n",
        "        return [tf.keras.layers.Input(shape=modality.config.input_shape) for modality in self._modalities_list]\n",
        "\n",
        "    def _build_classification_layer(self, features):\n",
        "        x = tf.keras.layers.Dense(units=self._fc_units, activation=self._activation)(features)\n",
        "        return tf.keras.layers.Dense(units=1, activation='sigmoid')(x)\n",
        "\n",
        "    def _build_LSTM_block(self, inputs):\n",
        "        outputs = []\n",
        "        for i in range(0, len(inputs)):\n",
        "            outputs.append(self.apply_lstm(inputs[i]))\n",
        "\n",
        "        return tf.stack(outputs, axis=1)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eP1lbqhpE5SC",
        "outputId": "9948802c-4a45-4c38-cce4-fbc1a085e7d6"
      },
      "source": [
        "modalities = [\n",
        "        DatasetFeaturesSet.VIDEO_FACE,\n",
        "        DatasetFeaturesSet.AUDIO,\n",
        "        DatasetFeaturesSet.PULSE,\n",
        "        DatasetFeaturesSet.VIDEO_SCENE,\n",
        "    ]\n",
        "\n",
        "model = MultimodalModel(\n",
        "    fusion_type='fbp',\n",
        "    modalities_list=modalities,\n",
        "    dropout=0.2,\n",
        "    fc_units=48,\n",
        "    first_layer=128,\n",
        "    second_layer=64,\n",
        "    learning_rate=tf.keras.optimizers.schedules.ExponentialDecay(0.0001 * 0.1, decay_steps=2000, decay_rate=0.9, staircase=True),\n",
        "    cp_dir=\"/content/drive/MyDrive/deception_dataset/experiments/multimodal_deception_pulse/checkpoint/fbp_VIDEO_FACE\",\n",
        "    trained=True,\n",
        "    cp_name=CHECKPOINT_NAME\n",
        ")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[<KerasTensor: shape=(None, 320, 512) dtype=float32 (created by layer 'input_2')>, <KerasTensor: shape=(None, 20, 512) dtype=float32 (created by layer 'input_3')>, <KerasTensor: shape=(None, 476, 2, 1) dtype=float32 (created by layer 'input_4')>, <KerasTensor: shape=(None, 320, 25088) dtype=float32 (created by layer 'input_5')>]\n",
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_4 (InputLayer)            [(None, 476, 2, 1)]  0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d (Conv2D)                 (None, 120, 1, 16)   7632        input_4[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d (MaxPooling2D)    (None, 60, 1, 16)    0           conv2d[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "input_2 (InputLayer)            [(None, 320, 512)]   0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_3 (InputLayer)            [(None, 20, 512)]    0                                            \n",
            "__________________________________________________________________________________________________\n",
            "reshape (Reshape)               (None, 60, 16)       0           max_pooling2d[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "input_5 (InputLayer)            [(None, 320, 25088)] 0                                            \n",
            "__________________________________________________________________________________________________\n",
            "lstm (LSTM)                     (None, 320, 128)     328192      input_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "lstm_2 (LSTM)                   (None, 20, 128)      328192      input_3[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "lstm_4 (LSTM)                   (None, 60, 128)      74240       reshape[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "lstm_6 (LSTM)                   (None, 320, 128)     12911104    input_5[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "lstm_1 (LSTM)                   (None, 64)           49408       lstm[0][0]                       \n",
            "__________________________________________________________________________________________________\n",
            "lstm_3 (LSTM)                   (None, 64)           49408       lstm_2[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "lstm_5 (LSTM)                   (None, 64)           49408       lstm_4[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "lstm_7 (LSTM)                   (None, 64)           49408       lstm_6[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "tf.stack (TFOpLambda)           (None, 4, 64)        0           lstm_1[0][0]                     \n",
            "                                                                 lstm_3[0][0]                     \n",
            "                                                                 lstm_5[0][0]                     \n",
            "                                                                 lstm_7[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "factorized_pooling_fusion_layer (None, 16)           32          tf.stack[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "dense (Dense)                   (None, 48)           816         factorized_pooling_fusion_layer[0\n",
            "__________________________________________________________________________________________________\n",
            "dense_1 (Dense)                 (None, 1)            49          dense[0][0]                      \n",
            "==================================================================================================\n",
            "Total params: 13,847,889\n",
            "Trainable params: 13,847,889\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eawHfChueeSi",
        "outputId": "bf3bebc1-0168-4475-a3a1-fcce994b5083"
      },
      "source": [
        "_, epoch = model.load()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/MyDrive/deception_dataset/experiments/multimodal_deception_pulse/checkpoint/fbp_VIDEO_FACE/cp-0020.ckpt\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tsh8W00wJqyH",
        "outputId": "e5b46067-6fe6-4bcd-ba41-1fd5ad324916"
      },
      "source": [
        "epoch"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "20"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ILLKavH5x1L8"
      },
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "from base.base_dataset_processor import BaseDatasetProcessor\n",
        "from configs.dataset.modality import DatasetFeaturesSet\n",
        "\n",
        "\n",
        "class MultimodalDatasetFeaturesProcessor(BaseDatasetProcessor):\n",
        "\n",
        "    def __init__(self, modalities_list):\n",
        "        self._modalities_list = modalities_list\n",
        "\n",
        "    def pre_process(self, dataset: tf.data.Dataset, parallel_calls: int):\n",
        "        dataset = dataset.map(self._extract_specified_modalities_and_ensure_shape, num_parallel_calls=parallel_calls)\n",
        "        dataset = dataset.map(self.concat_with_labels, num_parallel_calls=parallel_calls)\n",
        "        return dataset\n",
        "\n",
        "    @tf.function\n",
        "    def concat_with_labels(self, example: tf.train.Example):\n",
        "        inputs = []\n",
        "        for modality in self._modalities_list:\n",
        "            inputs.append(tf.expand_dims(example[str(modality.name)], 0))\n",
        "\n",
        "        return (tuple(inputs),1 )\n",
        "\n",
        "    @tf.function\n",
        "    def _extract_specified_modalities_and_ensure_shape(self, example: tf.Tensor) -> dict:\n",
        "        tf_features_dict = {}\n",
        "        for modality in self._modalities_list:\n",
        "            data = example[str(modality.name)]\n",
        "            tf_features_dict[str(modality.name)] = tf.ensure_shape(data, modality.config.shape)\n",
        "\n",
        "        return tf_features_dict\n",
        "\n",
        "    @tf.function\n",
        "    def filter_nan(self, input_, output):\n",
        "        return not tf.reduce_any(tf.math.is_nan(input_)) and not tf.reduce_any(tf.math.is_nan(output))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u0ks8IyVi1mv"
      },
      "source": [
        "ress = []\n",
        "shapes_dict= {}\n",
        "\n",
        "for d in features:\n",
        "  res = {}\n",
        "  for modality in modalities:\n",
        "    res.update({modality.name: d[modality]})\n",
        "    shapes_dict.update({modality.name: modality.config.shape})\n",
        "  ress.append(res)\n",
        "  \n",
        "def meta_dict_gen():\n",
        "  for res in ress:\n",
        "   yield res"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7xdAiV4O5POC"
      },
      "source": [
        "dataset = tf.data.Dataset.from_generator(\n",
        "  meta_dict_gen,\n",
        "  output_types={k: tf.float32 for k in shapes_dict},\n",
        "  output_shapes=shapes_dict)\n",
        "\n",
        "processor = MultimodalDatasetFeaturesProcessor(modalities_list=modalities)\n",
        "ds = processor.pre_process(dataset, parallel_calls=10)\n",
        "predictions = model.get_test_model().predict(ds)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j13h5-6vsbnj",
        "outputId": "fac5bd1f-3f86-496e-ac47-df99c7a0ba3c"
      },
      "source": [
        "np.squeeze(predictions)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.2618021 , 0.16087417, 0.14773522, 0.13859892, 0.15713096,\n",
              "       0.25025815, 0.43769652, 0.42819574, 0.5069501 , 0.4177396 ,\n",
              "       0.5697479 , 0.15955484, 0.1443656 , 0.17846479, 0.36439928,\n",
              "       0.49246886, 0.4897978 , 0.4876414 , 0.4870885 , 0.48972693,\n",
              "       0.4875653 ], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nkp12Am_sqGU"
      },
      "source": [
        "import seaborn as sns\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 565
        },
        "id": "8HNvuKA4sfhc",
        "outputId": "8c5751e3-1dbd-470f-efca-028a5918d2f0"
      },
      "source": [
        "result_data = np.squeeze(predictions)\n",
        "visualize_data = [result_data]\n",
        "xSigns = [10*i for i in range(len(result_data))]\n",
        "ySigns = [\"False\"]\n",
        "ax = sns.heatmap(visualize_data, vmin=0, vmax=1, cmap=\"bwr\", xticklabels=xSigns, yticklabels=ySigns)\n",
        "print('Results by each 10 seconds: ')\n",
        "plt.show()\n",
        "ax = sns.heatmap([[visualize_data[0].mean()]], vmin=0, vmax=1, cmap=\"bwr\")\n",
        "print('Mean result: ')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Results by each 10 seconds: \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Mean result: \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DD4jrBPosgGU"
      },
      "source": [
        "## Оценка модели"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Pks2cl047Uf4",
        "outputId": "35d02916-1e83-4298-a00c-04780549b2f7"
      },
      "source": [
        "from dataset.manager.data_manager import DataManager\n",
        "\n",
        "DATASET_TF_RECORDS_PATH = \"/content/drive/MyDrive/deception_dataset/tmp/deception_dataset_features\"\n",
        "from dataset.preprocessor.multimodal_dataset_features_processor import MultimodalDatasetFeaturesProcessor\n",
        "data_manager = DataManager(\n",
        "            tf_record_path=DATASET_TF_RECORDS_PATH,\n",
        "            batch_size=4)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Dataset files: ['/content/drive/MyDrive/deception_dataset/tmp/deception_dataset_features/deception_dataset_features-1.tfrecords', '/content/drive/MyDrive/deception_dataset/tmp/deception_dataset_features/deception_dataset_features-10.tfrecords', '/content/drive/MyDrive/deception_dataset/tmp/deception_dataset_features/deception_dataset_features-11.tfrecords', '/content/drive/MyDrive/deception_dataset/tmp/deception_dataset_features/deception_dataset_features-12.tfrecords', '/content/drive/MyDrive/deception_dataset/tmp/deception_dataset_features/deception_dataset_features-13.tfrecords', '/content/drive/MyDrive/deception_dataset/tmp/deception_dataset_features/deception_dataset_features-14.tfrecords', '/content/drive/MyDrive/deception_dataset/tmp/deception_dataset_features/deception_dataset_features-15.tfrecords', '/content/drive/MyDrive/deception_dataset/tmp/deception_dataset_features/deception_dataset_features-16.tfrecords', '/content/drive/MyDrive/deception_dataset/tmp/deception_dataset_features/deception_dataset_features-2.tfrecords', '/content/drive/MyDrive/deception_dataset/tmp/deception_dataset_features/deception_dataset_features-3.tfrecords', '/content/drive/MyDrive/deception_dataset/tmp/deception_dataset_features/deception_dataset_features-4.tfrecords', '/content/drive/MyDrive/deception_dataset/tmp/deception_dataset_features/deception_dataset_features-5.tfrecords', '/content/drive/MyDrive/deception_dataset/tmp/deception_dataset_features/deception_dataset_features-6.tfrecords', '/content/drive/MyDrive/deception_dataset/tmp/deception_dataset_features/deception_dataset_features-7.tfrecords', '/content/drive/MyDrive/deception_dataset/tmp/deception_dataset_features/deception_dataset_features-8.tfrecords', '/content/drive/MyDrive/deception_dataset/tmp/deception_dataset_features/deception_dataset_features-9.tfrecords']\n",
            "Train files size: 11\n",
            "Valid files size: 5\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FulHKKe3CdQO",
        "outputId": "6295915d-2893-49c0-d98c-3311d490ae68"
      },
      "source": [
        "valid = data_manager.build_validation_dataset( MultimodalDatasetFeaturesProcessor(modalities_list=modalities))\n",
        "\n",
        "valid_numpy_dataset_y = []\n",
        "for x in valid.as_numpy_iterator():\n",
        "    valid_numpy_dataset_y.extend(x[1])\n",
        "valid_numpy_dataset_y = np.asarray(valid_numpy_dataset_y)\n",
        "print(valid_numpy_dataset_y.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(160, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1tlv6MIxCzly"
      },
      "source": [
        "cnn_predicted = model.get_test_model().predict(valid)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IZxgP4olC715"
      },
      "source": [
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy\n",
        "from sklearn.externals._arff import xrange\n",
        "from sklearn.metrics import roc_curve, confusion_matrix\n",
        "\n",
        "\n",
        "def plot_binary_classification(y_test, predicted, predicted_prob, name):\n",
        "    predicted = numpy.around(predicted, 0)\n",
        "    if predicted_prob is not None:\n",
        "        # Show ROC curve\n",
        "        fpr, tpr, threshold = roc_curve(y_test, predicted_prob)\n",
        "        print(\"rates\")\n",
        "        print(fpr)\n",
        "        print(tpr)\n",
        "        print(\"ROC threshold\")\n",
        "        print(threshold)\n",
        "        plt.plot(fpr, tpr)\n",
        "        plt.title('ROC curve: ' + name)\n",
        "        plt.xlabel('false positive rate')\n",
        "        plt.ylabel('true positive rate')\n",
        "        plt.xlim(0, )\n",
        "        plt.ylim(0, )\n",
        "        plt.show()\n",
        "\n",
        "    # Show confusion matrix\n",
        "    cm = confusion_matrix(y_test, predicted)\n",
        "    print(cm)\n",
        "    plt.figure(figsize=(7, 7))\n",
        "    plt.imshow(cm, interpolation='nearest', cmap='Pastel1')\n",
        "    plt.title('Confusion matrix: ' + name, size=10)\n",
        "    plt.colorbar()\n",
        "    tick_marks = numpy.arange(2)\n",
        "    plt.xticks(tick_marks, [\"Deception\", \"Truth\"], size=10)\n",
        "    plt.yticks(tick_marks, [\"Deception\", \"Truth\"], size=10)\n",
        "    plt.tight_layout()\n",
        "    plt.ylabel('Actual label', size=10)\n",
        "    plt.xlabel('Predicted label', size=10)\n",
        "    width, height = cm.shape\n",
        "    for x in xrange(width):\n",
        "        for y in xrange(height):\n",
        "            plt.annotate(str(cm[x][y]), xy=(y, x),\n",
        "                         horizontalalignment='center',\n",
        "                         verticalalignment='center',\n",
        "                         size=20)\n",
        "    plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "Gt2lDswlC2Jd",
        "outputId": "02035bfa-ee35-4f49-da2c-8f43b929f66a"
      },
      "source": [
        "plot_binary_classification( valid_numpy_dataset_y, cnn_predicted,\n",
        "                                                 cnn_predicted,\n",
        "                                                 \"Mulimodal deception detction\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "rates\n",
            "[0.         0.         0.         0.01234568 0.01234568 0.02469136\n",
            " 0.02469136 0.03703704 0.03703704 0.09876543 0.09876543 0.11111111\n",
            " 0.11111111 0.13580247 0.13580247 0.14814815 0.14814815 0.19753086\n",
            " 0.19753086 0.24691358 0.24691358 0.28395062 0.28395062 1.        ]\n",
            "[0.         0.01265823 0.73417722 0.73417722 0.81012658 0.81012658\n",
            " 0.82278481 0.82278481 0.84810127 0.84810127 0.87341772 0.87341772\n",
            " 0.88607595 0.88607595 0.92405063 0.92405063 0.93670886 0.93670886\n",
            " 0.94936709 0.94936709 0.98734177 0.98734177 1.         1.        ]\n",
            "ROC threshold\n",
            "[1.9393094  0.9393094  0.8878148  0.87950325 0.85598654 0.8525013\n",
            " 0.8513418  0.84532297 0.820944   0.64267826 0.5438639  0.5331279\n",
            " 0.501048   0.49058792 0.48932466 0.4892266  0.4887392  0.4883536\n",
            " 0.48824537 0.4877574  0.48762357 0.48707113 0.48705366 0.05564524]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "text": [
            "[[72  9]\n",
            " [ 9 70]]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 504x504 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rD-p9iKxDWBg"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}